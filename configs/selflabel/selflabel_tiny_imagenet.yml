# setup
setup: selflabel

model_kwargs:
   head: mlp
   features_dim: 128
   nheads: 1
   nclusters: 200

# ema
use_ema: False

# Threshold
confidence_threshold: 0.98

# Loss
criterion: confidence-cross-entropy
criterion_kwargs:
    temperature: 0.1
    apply_class_balancing: True

# Model
backbone: resnet34
num_heads: 1

# Dataset
train_db_name: tiny_imagenet
val_db_name: tiny_imagenet
num_classes: 200
num_neighbors: 5

# Transformations
augmentation_strategy: both 
augmentation_kwargs:
   random_resized_crop:
      size: 64
      scale: [0.2, 1.0]
   color_jitter_random_apply:
      p: 0.8
   color_jitter:
      brightness: 0.4
      contrast: 0.4
      saturation: 0.4
      hue: 0.1
   random_grayscale: 
      p: 0.2
   normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]
strong_augmentation_kwargs:
   num_strong_augs: 5
   prob_strong_augs: 10

transformation_kwargs:
   resize: 80
   crop_size: 64
   normalize:
      mean: [0.485, 0.456, 0.406]
      std: [0.229, 0.224, 0.225]

# Hyperparameters
optimizer: adam
optimizer_kwargs:
   lr: 0.0001
   weight_decay: 0.0001
epochs: 200
batch_size: 128
num_workers: 8
beta: 10

# Scheduler
scheduler: constant
